# FUNDAMENTAL TRUTHS ABOUT AI

**From the perspective of a person standing in the middle of it.**

February 2026

-----

## The Two Axioms

**AI is currently the stupidest it will ever be for the rest of forever.**

This is not a prediction. It is a trend with no visible ceiling. Every six months the thing that was impossible becomes a demo, and the thing that was a demo becomes a commodity. If you are making plans based on what AI cannot do today, you are building on ground that is actively disappearing beneath you.

**What we know today may not be true tomorrow.**

This is not standard-issue "things change" wisdom. It is specific to AI in a way it is not specific to other fields. In most domains, knowledge accumulates. In AI, knowledge about AI *invalidates*. The expert opinion from eighteen months ago is not just outdated — it is actively misleading. The person who tells you what AI will never be able to do is almost certainly wrong. The person who tells you what AI will be able to do next year is probably also wrong, but in the other direction.

-----

## What Has Been Decimated

Be honest about what is gone. Not reassigned. Not elevated. Gone.

**Execution as a source of individual value.**

If your value was "I can write the code," that value has been decimated. Not because AI writes better code than you — it often doesn't — but because the gap between "person who can write code" and "person who cannot but has AI" has collapsed to nearly zero for most tasks. The skill that took you ten years to build can now be approximated in ten minutes by someone with no training and a clear description of what they want. The floor rose to meet the ceiling.

This is not theoretical. This is happening now across software engineering, copywriting, graphic design, data analysis, legal research, and every other field where the core work product is an artifact that can be described in language.

**Knowledge as a moat.**

"I know how to do X" used to be a defensible position. It is not anymore. The person who memorized the API, who knows the framework quirks, who has the obscure syntax committed to muscle memory — that person's advantage has been neutralized. Not because knowing things is worthless, but because *not knowing things is no longer expensive.* Access to knowledge was the bottleneck. The bottleneck has been removed.

**Speed as a differentiator.**

"I can do it faster" mattered when the baseline was other humans. The baseline is no longer other humans. Being the fastest coder in the room is like being the fastest calculator in the room after 1975. It is still impressive. It is no longer economically relevant.

**Volume as a signal of effort.**

The ability to produce large quantities of work used to signal dedication, capability, and value. A person who could write fifty pages, ship ten features, or analyze a hundred data sets was clearly working hard and clearly capable. That signal is now meaningless. Volume is free. Anyone can produce volume. The person who writes fifty pages may have spent forty-five seconds on them.

-----

## What Cannot Be Decimated

Some things have become *more* valuable precisely because everything around them got cheaper.

**Taste.**

Knowing what is good. Not what is correct — AI can check correctness. Not what is complete — AI can check completeness. Knowing what is *good.* What feels right. What will resonate. What to cut. What to keep. What to ship and what to kill. This is the thing that cannot be approximated because it requires a point of view, and a point of view requires a life. AI does not have a life. It has a training set.

Taste is what separates the person who asks AI to generate ten options and picks the best one from the person who asks AI to generate ten options and cannot tell the difference between them. The first person is more powerful than they have ever been. The second person is in trouble.

**Judgment under ambiguity.**

When the problem is well-defined, AI is better than you. Accept it. But most consequential decisions are not well-defined problems. They are situations where the constraints are unclear, the information is incomplete, the stakeholders disagree, the tradeoffs are real, and there is no objectively correct answer. This is where humans still operate and AI does not — not because AI lacks intelligence, but because ambiguity requires *commitment.* It requires someone to say "we are going this way" and own the consequences. AI will give you five options with tradeoffs. It will not bet the company.

**The question before the question.**

AI is extraordinarily good at answering questions. It is not good at knowing which question to ask. The distance between "solve this problem" and "notice that this is the problem that needs solving" is enormous, and it is almost entirely a human distance. The person who identifies the right problem is now infinitely more valuable than the person who solves the given one, because solving the given one is nearly free.

**Relationships and trust.**

No one cares whether the code was written by you or an AI. They care whether *you* stand behind it. They care whether you will be there when it breaks. They care whether you understand their situation, not just their ticket. The relational layer of work — the part where a human chooses to trust another human with something that matters — has not been touched by AI. If anything it has become more important, because in a world where anyone can produce anything, the question of *who* you work with becomes the primary filter.

**Conviction.**

The willingness to have an opinion and defend it. AI is a consensus machine. It gives you the weighted average of all perspectives in its training data, hedged and qualified. This is useful for research. It is useless for leadership. The person who says "this is what I believe and here is why, and I understand you disagree" has a kind of value that AI structurally cannot provide.

-----

## What Skills Matter Now

Given all of this, here is what an individual should actually invest in:

**1. Problem identification over problem solving.**

Stop getting faster at solving problems. Start getting better at finding the right ones. The ability to look at a system — a codebase, a business, a team — and say "this is what is actually wrong" is now the highest-leverage skill a person can have. Everything downstream of that identification can be automated. The identification itself cannot.

**2. Directing over doing.**

This is the hardest transition for skilled people. If you are good at writing code, good at writing prose, good at designing systems — your instinct is to do the work yourself because you know you will do it well. That instinct is now a liability. The person who can direct ten AI agents to do the work of ten people, while maintaining quality and coherence, is worth more than the person who does one person's work excellently. This is not a statement about fairness. It is a statement about leverage.

**3. Editing over generating.**

Generation is free. Editing is not. The ability to take something that is 80% right and make it 100% right — to see what is missing, what is wrong, what rings false — is now the core skill in any creative or technical field. The person who can edit is the person who ships. The person who can only generate is the person who produces drafts.

**4. Communication as architecture.**

The ability to describe what you want — precisely, completely, unambiguously — is now a *technical* skill. It is not soft. It is not supplementary. It is the primary interface between human intent and machine execution. The person who communicates well gets better output from AI, better alignment from teams, and better outcomes from every interaction. This has always been true. It is now true to a degree that makes it the single most important skill in most roles.

**5. Speed of adaptation.**

Not the speed at which you execute, but the speed at which you let go of what was true yesterday. The tools will change. The capabilities will change. The best practices will change. The person who can drop their mental model and rebuild it in a week will consistently outperform the person who clings to the model that worked six months ago. This is not about being trendy. It is about being calibrated to reality as it currently exists.

-----

## The Uncomfortable Summary

The value of *doing things* has collapsed. The value of *knowing which things to do* has exploded. The value of *being a person that other people trust* has not changed and probably never will.

If you built your career on execution, you are in a race you will lose. Not because you are slow, but because your competitor does not eat, does not sleep, and gets smarter every quarter.

If you built your career on judgment, taste, and relationships, you are holding assets that just appreciated dramatically — because now your judgment gets executed at machine speed instead of human speed.

The individual who thrives is not the one who fights AI for the work. It is the one who accepts that the work has been commoditized and asks: *what was I doing that was never about the work in the first place?*

That is where *some* of the value lives.

But not all of it. And probably not the most important part.

-----

## The Part That Is Not About Value

Everything above frames this in terms of value — economic value, career value, leverage, competitive advantage. That framing is useful. It is also incomplete in a way that matters.

Because there is a version of this conversation that the economics people will never have, which is: **some things are worth doing even when they produce no value at all.**

A person who writes code because they love the act of writing code has not been decimated by AI. Their *market position* may have shifted, but the thing itself — the satisfaction of solving a puzzle, the flow state, the quiet pleasure of making something work — is untouched. AI did not take that. AI cannot take that. You can still build a chair with hand tools even though factories exist. The chair is not the point.

The mistake is letting the economic argument colonize everything. Yes, execution-as-commodity is real. Yes, you need to adapt professionally. But if you let "where does the value live" become the only question you ask, you will optimize yourself into a perfectly leveraged, high-judgment, taste-having person who has lost the thread of why any of this mattered to them in the first place.

**The doing was never just about the output.** It was about the identity, the craft, the process. It was about being the kind of person who builds things. AI changes what the market will pay you for. It does not change what is worth doing with your time on earth.

So there are actually two games now:

**The economic game**, where the rules have changed and everything in this document applies — direct instead of do, judge instead of execute, leverage taste and relationships and the ability to identify the right problem.

**The human game**, where the rules have not changed at all — do the things that make you feel alive, build things because building is good, learn things because learning is good, and do not let a market correction in the value of execution trick you into believing that execution was never meaningful.

The people who will navigate this the best are not the ones who pick one game. They are the ones who play both without confusing which one they are in.

-----

## The Part Nobody Is Talking About

Everything above is about surviving a shift. Protecting what you have. Adapting to loss. It is the language of defense.

But here is what gets missed when the entire conversation is about what AI takes away: **it is now possible for one person to do what used to require fifty.**

Not fifty people's worth of grunt work. Fifty people's worth of *capability.* One person can build a product, ship it, market it, support it, iterate on it. One person can stand up infrastructure that used to require a team and a budget. One person can explore an idea that would have died in a planning meeting because it "wasn't worth the resources."

This has never been true before. Not like this.

The entire history of ambitious work has been a story of coordination costs. You had the idea, but you needed a team. You needed funding to pay the team. You needed management to coordinate the team. You needed process to keep the team aligned. By the time the work started, the original idea had been negotiated, compromised, and diluted by the realities of getting thirty humans to move in the same direction.

That constraint is dissolving. Not gone — there are still things that require human teams and always will be. But the threshold has moved dramatically. The class of things a single person with taste, judgment, and conviction can pull off has expanded by an order of magnitude, and it is still expanding.

This means something specific: **the bottleneck on ambition has shifted from resources to imagination.**

The person who could never build the thing because they did not have the team, the budget, the time — that person can now build the thing. The question is no longer "can I?" It is "should I?" and "what exactly?" Those are better questions. Those are the questions that taste and judgment were made for.

So the real picture is not two games. It is three:

**The economic game** — adapt or become irrelevant. Direct instead of do. The rules changed.

**The human game** — do not let the economic game consume your identity. The craft matters. The doing matters. Build the chair with hand tools on the weekend.

**The builder's game** — the new one, the one that did not exist before. What would you build if the only constraint was your own clarity about what is worth building? Because that is approximately the constraint you are now operating under. Not zero cost, not zero effort, but close enough that the bottleneck has moved from *capability* to *vision.*

The people who will define this era are not the ones who best adapt to what AI takes away. They are the ones who see what AI makes possible and have the taste to do it well, the judgment to do it right, and the conviction to do it at all.
